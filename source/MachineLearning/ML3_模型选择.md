模型选择
===================================
学习算法设计中一个关键问题是假设集合$\mathcal{H}$的选择，这被称为模型选择问题。

当一个样本的标签可以有某个唯一的可测函数$f:\mathcal{X}\rightarrow\mathcal{Y}$（以概率1成立时），这种情况被称作**确定性情境**。此时，考虑一个输入空间服从的分布$\mathcal{D}$，依分布$\mathcal{D}$采样得到的训练样本$(x_1,x_2,...,x_n)$，并且通过$f:y_i=f(x_i)，i\in[1,n]$确定对应的标签。很多学习问题都可以在此确定性情形下完成形式化。根据定义可知，存在一个没有泛化误差的目标函数使得$R(h)=0$

我们推广到更加常见的**随机性情境**。此时机器学习要解决的问题是，找到一个有较小泛化误差的假设$h\in\mathcal{H}$

$$R(h)=\underset{(x,y)\sim\mathcal{D}}{\mathbb{P}}[h(x)\neq y]$$

此时学习算法输出的标签是输入的一个概率函数。例如想用一个人的身高和体重推断这个人的性别，标签往往不是唯一的，对于大多数输入，男生和女生都是可能的性别。对于每个固定的输入(年龄，身高，体重...)，其输出的标签为男性对应的是一个概率分布。

**贝叶斯误差:** *给定一个在$\mathcal{X\times Y}$上的分布$\mathcal{D}$，响应的贝叶斯误差$R^*$定义为由可测函数类$h:\mathcal{X\rightarrow Y}$产生的误差下界：*

$$R^*=\underset{h(可测)}{inf} R(h)$$

*一个满足$R(h)=R^*$的假设$h$被称为贝叶斯假设或贝叶斯分类器。*

根据上述定义，对于确定性情境$R^*=0$，对于随机性情境$R^*\neq 0$


